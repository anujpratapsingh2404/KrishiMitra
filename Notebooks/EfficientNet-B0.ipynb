{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf448d5d-1a31-4406-a7f8-286fe5a82878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3050 Laptop GPU, compute capability 8.6\n",
      "Total samples: 73000\n",
      "Training samples: 58400\n",
      "Validation samples: 7300\n",
      "Test samples: 7300\n",
      "Number of classes: 73\n",
      "Found 58400 validated image filenames belonging to 73 classes.\n",
      "Found 7300 validated image filenames belonging to 73 classes.\n",
      "Found 7300 validated image filenames belonging to 73 classes.\n",
      "Steps per epoch: 912\n",
      "Validation steps: 114\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.mixed_precision import set_global_policy\n",
    "\n",
    "set_global_policy('mixed_float16')\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        \n",
    "data_dir = 'D:/Major Project/Dataset/Masked_Dataset'\n",
    "image_paths = []\n",
    "labels = []\n",
    "classes = sorted(os.listdir(data_dir))\n",
    "\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    for img_name in os.listdir(class_dir):\n",
    "        if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            image_paths.append(img_path)\n",
    "            labels.append(class_name)\n",
    "\n",
    "df = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
    "\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "print(f\"Number of classes: {len(classes)}\")\n",
    "\n",
    "batch_size = 64\n",
    "target_size = (224, 224)\n",
    "num_classes = len(classes)\n",
    "num_workers = 4\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    workers=num_workers,\n",
    "    use_multiprocessing=True\n",
    ")\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    workers=num_workers,\n",
    "    use_multiprocessing=True\n",
    ")\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,\n",
    "    workers=num_workers,\n",
    "    use_multiprocessing=True\n",
    ")\n",
    "\n",
    "def generator_to_tfdata(generator):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: generator,\n",
    "        output_types=(tf.float32, tf.float32),\n",
    "        output_shapes=([None, 224, 224, 3], [None, num_classes])\n",
    "    )\n",
    "    return dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset = generator_to_tfdata(train_generator)\n",
    "val_dataset = generator_to_tfdata(val_generator)\n",
    "test_dataset = generator_to_tfdata(test_generator)\n",
    "\n",
    "steps_per_epoch = len(train_df) // batch_size\n",
    "validation_steps = len(val_df) // batch_size\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Validation steps: {validation_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bef1f669-bfe2-4152-a73c-8a65c6d03820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CommunicationImplementation.AUTO\n",
      "Initial Model (Base Layers Frozen):\n",
      "Total parameters: 4222956\n",
      "Trainable parameters: 173385\n",
      "Non-trainable parameters: 4049571\n",
      "Epoch 1/50\n",
      "912/912 [==============================] - 710s 757ms/step - loss: 0.9740 - accuracy: 0.7214 - val_loss: 0.5665 - val_accuracy: 0.8052\n",
      "Epoch 2/50\n",
      "912/912 [==============================] - 636s 698ms/step - loss: 0.4846 - accuracy: 0.8392 - val_loss: 0.3861 - val_accuracy: 0.8704\n",
      "Epoch 3/50\n",
      "912/912 [==============================] - 620s 680ms/step - loss: 0.3993 - accuracy: 0.8636 - val_loss: 0.3594 - val_accuracy: 0.8753\n",
      "Epoch 4/50\n",
      "912/912 [==============================] - 609s 668ms/step - loss: 0.3542 - accuracy: 0.8774 - val_loss: 0.3159 - val_accuracy: 0.8881\n",
      "Epoch 5/50\n",
      "912/912 [==============================] - 605s 664ms/step - loss: 0.3225 - accuracy: 0.8873 - val_loss: 0.2783 - val_accuracy: 0.9026\n",
      "Epoch 6/50\n",
      "912/912 [==============================] - 600s 658ms/step - loss: 0.3009 - accuracy: 0.8948 - val_loss: 0.2847 - val_accuracy: 0.8990\n",
      "Epoch 7/50\n",
      "912/912 [==============================] - 599s 657ms/step - loss: 0.2785 - accuracy: 0.9010 - val_loss: 0.2678 - val_accuracy: 0.9034\n",
      "Epoch 8/50\n",
      "912/912 [==============================] - 598s 656ms/step - loss: 0.2669 - accuracy: 0.9061 - val_loss: 0.2526 - val_accuracy: 0.9095\n",
      "Epoch 9/50\n",
      "912/912 [==============================] - 600s 658ms/step - loss: 0.2558 - accuracy: 0.9091 - val_loss: 0.2271 - val_accuracy: 0.9185\n",
      "Epoch 10/50\n",
      "912/912 [==============================] - 597s 654ms/step - loss: 0.2442 - accuracy: 0.9123 - val_loss: 0.2396 - val_accuracy: 0.9099\n",
      "Epoch 11/50\n",
      "912/912 [==============================] - 598s 656ms/step - loss: 0.2319 - accuracy: 0.9175 - val_loss: 0.2020 - val_accuracy: 0.9243\n",
      "Epoch 12/50\n",
      "912/912 [==============================] - 600s 658ms/step - loss: 0.2303 - accuracy: 0.9176 - val_loss: 0.2102 - val_accuracy: 0.9255\n",
      "Epoch 13/50\n",
      "912/912 [==============================] - 600s 658ms/step - loss: 0.2179 - accuracy: 0.9215 - val_loss: 0.2306 - val_accuracy: 0.9179\n",
      "Epoch 14/50\n",
      "912/912 [==============================] - 598s 656ms/step - loss: 0.2136 - accuracy: 0.9232 - val_loss: 0.1975 - val_accuracy: 0.9295\n",
      "Epoch 15/50\n",
      "912/912 [==============================] - 590s 647ms/step - loss: 0.2104 - accuracy: 0.9239 - val_loss: 0.2051 - val_accuracy: 0.9251\n",
      "Epoch 16/50\n",
      "912/912 [==============================] - 595s 653ms/step - loss: 0.2022 - accuracy: 0.9273 - val_loss: 0.1951 - val_accuracy: 0.9317\n",
      "Epoch 17/50\n",
      "912/912 [==============================] - 594s 651ms/step - loss: 0.1979 - accuracy: 0.9285 - val_loss: 0.1884 - val_accuracy: 0.9308\n",
      "Epoch 18/50\n",
      "912/912 [==============================] - 633s 694ms/step - loss: 0.1929 - accuracy: 0.9304 - val_loss: 0.2062 - val_accuracy: 0.9236\n",
      "Epoch 19/50\n",
      "912/912 [==============================] - 633s 694ms/step - loss: 0.1907 - accuracy: 0.9301 - val_loss: 0.2060 - val_accuracy: 0.9273\n",
      "Epoch 20/50\n",
      "912/912 [==============================] - 647s 709ms/step - loss: 0.1871 - accuracy: 0.9320 - val_loss: 0.1847 - val_accuracy: 0.9303\n",
      "Epoch 21/50\n",
      "912/912 [==============================] - 654s 717ms/step - loss: 0.1800 - accuracy: 0.9350 - val_loss: 0.1803 - val_accuracy: 0.9366\n",
      "Epoch 22/50\n",
      "912/912 [==============================] - 684s 750ms/step - loss: 0.1787 - accuracy: 0.9357 - val_loss: 0.1855 - val_accuracy: 0.9373\n",
      "Epoch 23/50\n",
      "912/912 [==============================] - 668s 733ms/step - loss: 0.1804 - accuracy: 0.9345 - val_loss: 0.1678 - val_accuracy: 0.9393\n",
      "Epoch 24/50\n",
      "912/912 [==============================] - 644s 706ms/step - loss: 0.1735 - accuracy: 0.9373 - val_loss: 0.1574 - val_accuracy: 0.9447\n",
      "Epoch 25/50\n",
      "912/912 [==============================] - 656s 720ms/step - loss: 0.1691 - accuracy: 0.9390 - val_loss: 0.1664 - val_accuracy: 0.9442\n",
      "Epoch 26/50\n",
      "912/912 [==============================] - 660s 724ms/step - loss: 0.1677 - accuracy: 0.9393 - val_loss: 0.1920 - val_accuracy: 0.9345\n",
      "Epoch 27/50\n",
      "912/912 [==============================] - 691s 758ms/step - loss: 0.1659 - accuracy: 0.9399 - val_loss: 0.1900 - val_accuracy: 0.9341\n",
      "Epoch 28/50\n",
      "912/912 [==============================] - 686s 753ms/step - loss: 0.1633 - accuracy: 0.9413 - val_loss: 0.1676 - val_accuracy: 0.9400\n",
      "Epoch 29/50\n",
      "912/912 [==============================] - 686s 753ms/step - loss: 0.1598 - accuracy: 0.9416 - val_loss: 0.1585 - val_accuracy: 0.9438\n",
      "Saved initial weights to 'initial_weights_efficientnetb0.h5'\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
    "with strategy.scope():\n",
    "    def build_model(num_classes):\n",
    "        base_model = EfficientNetB0(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "        x = base_model.output\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(128, activation='relu')(x)\n",
    "        predictions = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "        model = models.Model(inputs=base_model.input, outputs=predictions)\n",
    "        return model, base_model\n",
    "\n",
    "    model, base_model = build_model(num_classes)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "print(\"Initial Model (Base Layers Frozen):\")\n",
    "print(f\"Total parameters: {model.count_params()}\")\n",
    "print(f\"Trainable parameters: {sum([w.shape.num_elements() for w in model.trainable_weights])}\")\n",
    "print(f\"Non-trainable parameters: {model.count_params() - sum([w.shape.num_elements() for w in model.trainable_weights])}\")\n",
    "\n",
    "early_stopping_initial = EarlyStopping(monitor='val_accuracy', patience=5, mode='max', restore_best_weights=True)\n",
    "model_checkpoint_initial = ModelCheckpoint(\n",
    "    'D:/Major Project/efficientnet/best_initial_efficientnetb0_weights.h5',\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "history_initial = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=50,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stopping_initial, model_checkpoint_initial],\n",
    "    workers=num_workers,\n",
    "    use_multiprocessing=True,\n",
    "    verbose=1\n",
    ")\n",
    "history_df = pd.DataFrame(history_initial.history)\n",
    "history_df.to_csv('D:/Major Project/efficientnet/training_history_initial_efficientnetb0.csv', index=False)\n",
    "model.save_weights('D:/Major Project/efficientnet/initial_weights_efficientnetb0.h5')\n",
    "print(\"Saved initial weights to 'initial_weights_efficientnetb0.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fa119e9-bc9b-416f-9287-43a1c96c9af5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-Tuned Model (Last 17 Layers Unfrozen):\n",
      "Total parameters: 4222956\n",
      "Trainable parameters: 1302777\n",
      "Non-trainable parameters: 2920179\n",
      "Epoch 1/30\n",
      "912/912 [==============================] - 897s 961ms/step - loss: 0.6592 - accuracy: 0.7993 - val_loss: 0.3403 - val_accuracy: 0.8849 - lr: 1.0000e-05\n",
      "Epoch 2/30\n",
      "912/912 [==============================] - 793s 869ms/step - loss: 0.3824 - accuracy: 0.8710 - val_loss: 0.2686 - val_accuracy: 0.9054 - lr: 1.0000e-05\n",
      "Epoch 3/30\n",
      "912/912 [==============================] - 767s 841ms/step - loss: 0.3079 - accuracy: 0.8966 - val_loss: 0.2336 - val_accuracy: 0.9165 - lr: 1.0000e-05\n",
      "Epoch 4/30\n",
      "912/912 [==============================] - 765s 839ms/step - loss: 0.2704 - accuracy: 0.9074 - val_loss: 0.2101 - val_accuracy: 0.9234 - lr: 1.0000e-05\n",
      "Epoch 5/30\n",
      "912/912 [==============================] - 797s 874ms/step - loss: 0.2493 - accuracy: 0.9141 - val_loss: 0.1917 - val_accuracy: 0.9317 - lr: 1.0000e-05\n",
      "Epoch 6/30\n",
      "912/912 [==============================] - 779s 855ms/step - loss: 0.2237 - accuracy: 0.9217 - val_loss: 0.1809 - val_accuracy: 0.9365 - lr: 1.0000e-05\n",
      "Epoch 7/30\n",
      "912/912 [==============================] - 771s 846ms/step - loss: 0.2146 - accuracy: 0.9251 - val_loss: 0.1702 - val_accuracy: 0.9391 - lr: 1.0000e-05\n",
      "Epoch 8/30\n",
      "912/912 [==============================] - 754s 828ms/step - loss: 0.1987 - accuracy: 0.9295 - val_loss: 0.1635 - val_accuracy: 0.9416 - lr: 1.0000e-05\n",
      "Epoch 9/30\n",
      "912/912 [==============================] - 785s 861ms/step - loss: 0.1851 - accuracy: 0.9343 - val_loss: 0.1588 - val_accuracy: 0.9412 - lr: 1.0000e-05\n",
      "Epoch 10/30\n",
      "912/912 [==============================] - 787s 863ms/step - loss: 0.1793 - accuracy: 0.9353 - val_loss: 0.1477 - val_accuracy: 0.9471 - lr: 1.0000e-05\n",
      "Epoch 11/30\n",
      "912/912 [==============================] - 753s 826ms/step - loss: 0.1752 - accuracy: 0.9374 - val_loss: 0.1455 - val_accuracy: 0.9463 - lr: 1.0000e-05\n",
      "Epoch 12/30\n",
      "912/912 [==============================] - 758s 832ms/step - loss: 0.1671 - accuracy: 0.9402 - val_loss: 0.1428 - val_accuracy: 0.9472 - lr: 1.0000e-05\n",
      "Epoch 13/30\n",
      "912/912 [==============================] - 757s 830ms/step - loss: 0.1616 - accuracy: 0.9423 - val_loss: 0.1371 - val_accuracy: 0.9481 - lr: 1.0000e-05\n",
      "Epoch 14/30\n",
      "912/912 [==============================] - 767s 841ms/step - loss: 0.1561 - accuracy: 0.9443 - val_loss: 0.1353 - val_accuracy: 0.9494 - lr: 1.0000e-05\n",
      "Epoch 15/30\n",
      "912/912 [==============================] - 765s 839ms/step - loss: 0.1505 - accuracy: 0.9475 - val_loss: 0.1344 - val_accuracy: 0.9509 - lr: 1.0000e-05\n",
      "Epoch 16/30\n",
      "912/912 [==============================] - 734s 805ms/step - loss: 0.1456 - accuracy: 0.9483 - val_loss: 0.1275 - val_accuracy: 0.9522 - lr: 1.0000e-05\n",
      "Epoch 17/30\n",
      "912/912 [==============================] - 740s 812ms/step - loss: 0.1434 - accuracy: 0.9473 - val_loss: 0.1226 - val_accuracy: 0.9552 - lr: 1.0000e-05\n",
      "Epoch 18/30\n",
      "912/912 [==============================] - 745s 818ms/step - loss: 0.1413 - accuracy: 0.9492 - val_loss: 0.1252 - val_accuracy: 0.9529 - lr: 1.0000e-05\n",
      "Epoch 19/30\n",
      "912/912 [==============================] - 754s 827ms/step - loss: 0.1348 - accuracy: 0.9517 - val_loss: 0.1224 - val_accuracy: 0.9552 - lr: 1.0000e-05\n",
      "Epoch 20/30\n",
      "912/912 [==============================] - 759s 833ms/step - loss: 0.1285 - accuracy: 0.9546 - val_loss: 0.1173 - val_accuracy: 0.9560 - lr: 1.0000e-05\n",
      "Epoch 21/30\n",
      "912/912 [==============================] - 756s 829ms/step - loss: 0.1319 - accuracy: 0.9520 - val_loss: 0.1156 - val_accuracy: 0.9567 - lr: 1.0000e-05\n",
      "Epoch 22/30\n",
      "912/912 [==============================] - 744s 816ms/step - loss: 0.1251 - accuracy: 0.9550 - val_loss: 0.1130 - val_accuracy: 0.9601 - lr: 1.0000e-05\n",
      "Epoch 23/30\n",
      "912/912 [==============================] - 743s 815ms/step - loss: 0.1229 - accuracy: 0.9547 - val_loss: 0.1145 - val_accuracy: 0.9586 - lr: 1.0000e-05\n",
      "Epoch 24/30\n",
      "912/912 [==============================] - 742s 814ms/step - loss: 0.1198 - accuracy: 0.9569 - val_loss: 0.1121 - val_accuracy: 0.9586 - lr: 1.0000e-05\n",
      "Epoch 25/30\n",
      "912/912 [==============================] - 880s 965ms/step - loss: 0.1194 - accuracy: 0.9564 - val_loss: 0.1083 - val_accuracy: 0.9604 - lr: 1.0000e-05\n",
      "Epoch 26/30\n",
      "912/912 [==============================] - 751s 824ms/step - loss: 0.1151 - accuracy: 0.9575 - val_loss: 0.1073 - val_accuracy: 0.9607 - lr: 1.0000e-05\n",
      "Epoch 27/30\n",
      "912/912 [==============================] - 736s 808ms/step - loss: 0.1159 - accuracy: 0.9581 - val_loss: 0.1057 - val_accuracy: 0.9612 - lr: 1.0000e-05\n",
      "Epoch 28/30\n",
      "912/912 [==============================] - 741s 813ms/step - loss: 0.1127 - accuracy: 0.9594 - val_loss: 0.1089 - val_accuracy: 0.9613 - lr: 1.0000e-05\n",
      "Epoch 29/30\n",
      "912/912 [==============================] - 735s 806ms/step - loss: 0.1124 - accuracy: 0.9595 - val_loss: 0.1037 - val_accuracy: 0.9622 - lr: 1.0000e-05\n",
      "Epoch 30/30\n",
      "912/912 [==============================] - 818s 897ms/step - loss: 0.1077 - accuracy: 0.9614 - val_loss: 0.1034 - val_accuracy: 0.9631 - lr: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Fine Tuning\n",
    "def build_model(num_classes):\n",
    "    base_model =  EfficientNetB0(input_shape=(224, 224, 3), include_top=False, weights=None)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    predictions = layers.Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "    model = models.Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model, base_model\n",
    "\n",
    "model, base_model = build_model(num_classes)\n",
    "model.load_weights('D:/Major Project/efficientnet/initial_weights_efficientnetb0.h5')\n",
    "\n",
    "for layer in base_model.layers[-17:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(\"Fine-Tuned Model (Last 17 Layers Unfrozen):\")\n",
    "print(f\"Total parameters: {model.count_params()}\")\n",
    "print(f\"Trainable parameters: {sum([w.shape.num_elements() for w in model.trainable_weights])}\")\n",
    "print(f\"Non-trainable parameters: {model.count_params() - sum([w.shape.num_elements() for w in model.trainable_weights])}\")\n",
    "\n",
    "early_stopping_fine = EarlyStopping(monitor='val_accuracy', patience=3, mode='max', restore_best_weights=True)\n",
    "model_checkpoint_fine = ModelCheckpoint(\n",
    "    'D:/Major Project/efficientnet/best_fine_tuned_vgg16.keras',\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True\n",
    ")\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    epochs=30,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stopping_fine, model_checkpoint_fine, reduce_lr],\n",
    "    workers=num_workers,\n",
    "    use_multiprocessing=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history_fine_df = pd.DataFrame(history_fine.history)\n",
    "history_fine_df.to_csv('D:/Major Project/efficientnet/training_history_fine_vgg16.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7b59bf0-1fb9-40ee-8719-299ba4ca4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('D:/Major Project/efficientnet/all_weights.keras')\n",
    "model.save('D:/Major Project/efficientnet/final_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ea11c76-5988-457b-9612-6c930d96bc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 46s 389ms/step - loss: 0.1039 - accuracy: 0.9637\n",
      "Test Loss: 0.1039, Test Accuracy: 0.9637\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test set\n",
    "test_steps = len(test_df) // batch_size\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_steps)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53fa39ea-ff16-447f-a6b8-3c157d46c091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 48s 419ms/step - loss: 0.1039 - accuracy: 0.9637\n",
      "Test Loss: 0.1039, Test Accuracy: 0.9637\n",
      "114/114 [==============================] - 43s 379ms/step\n",
      "Confusion matrix with random subset of classes saved to 'D:/Major Project/efficientnet/confusion_matrix_random_subset.png'\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import seaborn as sns\n",
    "test_generator.reset()\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_steps, verbose=1)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "y_pred = model.predict(test_generator, steps=test_steps, verbose=1)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = test_generator.classes[:len(y_pred_classes)]\n",
    "if len(y_true) != len(y_pred_classes):\n",
    "    print(\"Warning: Mismatch in lengths. Truncating y_true to match y_pred_classes.\")\n",
    "    y_true = y_true[:len(y_pred_classes)]\n",
    "y_true = np.array(y_true)\n",
    "y_pred_classes = np.array(y_pred_classes)\n",
    "class_labels = ['Apple__Apple_scab', 'Apple_Black_rot', 'Apple_Cedar_apple_rust', 'Apple_healthy', 'BittergourdDowny_Mildew', 'BittergourdHealthy', 'BittergourdJassid', \n",
    "    'BittergourdLeafSpot', 'BittergourdNitrogen_Deficiency', 'BittergourdNitrogen_and_Magnesium_Deficiency', 'BittergourdNitrogen_and_Potassium_Deficiency', 'BittergourdPotassium_Deficiency', \n",
    "     'BittergourdPotassium_and_Magnesium_Deficiency', 'Blueberry_healthy', 'Cherry(including_sour)__Powdery_mildew', 'Cherry(including_sour)__healthy', \n",
    "     'Corn(maize)__Cercospora_leaf_spot Gray_leaf_spot', 'Corn(maize)__Common_rust', 'Corn_(maize)__Northern_Leaf_Blight', 'Corn(maize)__healthy', 'EggplantAphids', \n",
    "     'EggplantCercosporaLeafSpot', 'EggplantFleaBeetles', 'EggplantHealthy', 'EggplantLeafWilt', 'EggplantPhytophthoraBlight', 'EggplantPowderyMildew', 'EggplantTobaccoMosaicVirus',\n",
    "     'Grape_Black_rot', 'Grape_Esca(Black_Measles)', 'Grape__Leaf_blight(Isariopsis_Leaf_Spot)', 'Grape__healthy', 'LettuceBacterial', 'LettuceFungal', 'LettuceHealthy', \n",
    "     'Orange_Haunglongbing(Citrus_greening)', 'Papaya_Anthracanose_Diease', 'Papaya_Black_Spot_Diease', 'Papaya_Healthy', 'Papaya_Powdery_Mildery_Diease', 'Papaya_Ring_spot_Diease',\n",
    "     'Papaya_phytophthora_Disease', 'Peach__Bacterial_spot', 'Peach_healthy', 'Pepper,_bell_Bacterial_spot', 'Pepper,_bell_healthy', 'PigeonpeaHealthy', 'PigeonpeaLeafSpot', \n",
    "     'PigeonpeaLeafwebber', 'PigeonpeaSterilicmosaic', 'Potato_Early_blight', 'Potato_Late_blight', 'Potato_healthy', 'Raspberry_healthy', 'Soybean_healthy', 'Squash_Powdery_mildew',\n",
    "     'Strawberry_Leaf_scorch', 'Strawberry_healthy', 'SweetPumpkinDownyMildewDisease', 'SweetPumpkinHealthy', 'SweetPumpkinLeafCurlDisease', 'SweetPumpkinMosaicDisease', \n",
    "     'SweetPumpkinRedBeetle', 'Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_Late_blight', 'Tomato_Leaf_Mold', 'Tomato_Septoria_leaf_spot',\n",
    "     'Tomato_Spider_mites Two-spotted_spider_mite', 'Tomato_Target_Spot', 'Tomato_Tomato_Yellow_Leaf_Curl_Virus', 'Tomato_Tomato_mosaic_virus', 'Tomato__healthy']\n",
    "num_classes_to_show = 20\n",
    "if len(class_labels) < num_classes_to_show:\n",
    "    num_classes_to_show = len(class_labels)\n",
    "\n",
    "random_classes = random.sample(class_labels, num_classes_to_show)\n",
    "random_class_indices = [class_labels.index(cls) for cls in random_classes]\n",
    "mask_true = np.isin(y_true, random_class_indices)\n",
    "\n",
    "filtered_y_true_temp = y_true[mask_true]\n",
    "filtered_y_pred_temp = y_pred_classes[mask_true]\n",
    "mask_pred = np.isin(filtered_y_pred_temp, random_class_indices)\n",
    "\n",
    "filtered_y_true = filtered_y_true_temp[mask_pred]\n",
    "filtered_y_pred_classes = filtered_y_pred_temp[mask_pred]\n",
    "\n",
    "label_mapping = {idx: i for i, idx in enumerate(random_class_indices)}\n",
    "filtered_y_true_mapped = np.array([label_mapping[label] for label in filtered_y_true])\n",
    "filtered_y_pred_mapped = np.array([label_mapping[label] for label in filtered_y_pred_classes])\n",
    "\n",
    "cm = confusion_matrix(filtered_y_true_mapped, filtered_y_pred_mapped)\n",
    "\n",
    "plt.figure(figsize=(10, 10)) \n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=random_classes, yticklabels=random_classes,\n",
    "            cbar=False, linewidths=0.3, square=True)\n",
    "plt.xticks(rotation=90, fontsize=6)\n",
    "plt.yticks(fontsize=6)\n",
    "plt.xlabel('Predicted Labels', fontsize=8)\n",
    "plt.ylabel('True Labels', fontsize=8)\n",
    "plt.title('Confusion Matrix', fontsize=12)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('D:/Major Project/efficientnet/confusion_matrix_random_subset.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"Confusion matrix with random subset of classes saved to 'D:/Major Project/efficientnet/confusion_matrix_random_subset.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c100c5d3-8fdc-4e47-b101-ad55dfb1cf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report saved to 'D:/Major Project/efficientnet/classification_report.csv'\n",
      "\n",
      "Classification Report:\n",
      "                              precision    recall  f1-score      support\n",
      "Apple___Apple_scab             0.980000  0.980000  0.980000   100.000000\n",
      "Apple___Black_rot              1.000000  0.990000  0.994975   100.000000\n",
      "Apple___Cedar_apple_rust       1.000000  1.000000  1.000000   100.000000\n",
      "Apple___healthy                0.980000  0.989899  0.984925    99.000000\n",
      "Bittergourd__Downy_Mildew      0.979381  0.950000  0.964467   100.000000\n",
      "...                                 ...       ...       ...          ...\n",
      "Tomato___Tomato_mosaic_virus   0.989691  0.960000  0.974619   100.000000\n",
      "Tomato___healthy               0.931373  0.950000  0.940594   100.000000\n",
      "accuracy                       0.963679  0.963679  0.963679     0.963679\n",
      "macro avg                      0.965489  0.963688  0.963625  7296.000000\n",
      "weighted avg                   0.965516  0.963679  0.963636  7296.000000\n",
      "\n",
      "[76 rows x 4 columns]\n",
      "Test predictions saved to 'D:/Major Project/efficientnet/test_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "class_labels = list(test_generator.class_indices.keys())\n",
    "report = classification_report(y_true, y_pred_classes, target_names=class_labels, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.to_csv('D:/Major Project/efficientnet/classification_report.csv')\n",
    "print(\"Classification report saved to 'D:/Major Project/efficientnet/classification_report.csv'\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(report_df)\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    'True_Label': [class_labels[i] for i in y_true],\n",
    "    'Predicted_Label': [class_labels[i] for i in y_pred_classes],\n",
    "    'Confidence': np.max(y_pred, axis=1)\n",
    "})\n",
    "predictions_df.to_csv('D:/Major Project/efficientnet/test_predictions.csv', index=False)\n",
    "print(\"Test predictions saved to 'D:/Major Project/efficientnet/test_predictions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57417b82-0dfc-4acf-8c73-7a7a5abd47d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading history CSVs: [Errno 2] No such file or directory: 'D:/Major Project/efficientnet/training_history_fine_efficientnetb0.csv'\n",
      "Please ensure 'training_history_initial_efficientnetb0.csv' and 'training_history_fine_efficientnetb0.csv' exist in 'D:/Major Project/efficientnet/'\n",
      "Initial training epochs: 29\n",
      "Fine-tuning epochs: 30\n",
      "Total epochs: 59\n",
      "Training history plot saved to 'D:/Major Project/efficientnet/training_history.png'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    history_initial_df = pd.read_csv('D:/Major Project/efficientnet/training_history_initial_efficientnetb0.csv')\n",
    "    history_fine_df = pd.read_csv('D:/Major Project/efficientnet/training_history_fine_efficientnetb0.csv')\n",
    "    print(\"Loaded training history from 'training_history_initial_efficientnetb0.csv' and 'training_history_fine_efficientnetb0.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading history CSVs: {e}\")\n",
    "    print(\"Please ensure 'training_history_initial_efficientnetb0.csv' and 'training_history_fine_efficientnetb0.csv' exist in 'D:/Major Project/efficientnet/'\")\n",
    "    exit(1)\n",
    "\n",
    "required_columns = ['accuracy', 'val_accuracy', 'loss', 'val_loss']\n",
    "if not all(col in history_initial_df.columns for col in required_columns) or \\\n",
    "   not all(col in history_fine_df.columns for col in required_columns):\n",
    "    print(\"Error: CSV files must contain columns: 'accuracy', 'val_accuracy', 'loss', 'val_loss'\")\n",
    "    exit(1)\n",
    "\n",
    "history_initial = {\n",
    "    'accuracy': history_initial_df['accuracy'].tolist(),\n",
    "    'val_accuracy': history_initial_df['val_accuracy'].tolist(),\n",
    "    'loss': history_initial_df['loss'].tolist(),\n",
    "    'val_loss': history_initial_df['val_loss'].tolist()\n",
    "}\n",
    "history_fine = {\n",
    "    'accuracy': history_fine_df['accuracy'].tolist(),\n",
    "    'val_accuracy': history_fine_df['val_accuracy'].tolist(),\n",
    "    'loss': history_fine_df['loss'].tolist(),\n",
    "    'val_loss': history_fine_df['val_loss'].tolist()\n",
    "}\n",
    "print(f\"Initial training epochs: {len(history_initial['accuracy'])}\")\n",
    "print(f\"Fine-tuning epochs: {len(history_fine['accuracy'])}\")\n",
    "print(f\"Total epochs: {len(history_initial['accuracy']) + len(history_fine['accuracy'])}\")\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_initial['accuracy'] + history_fine['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history_initial['val_accuracy'] + history_fine['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_initial['loss'] + history_fine['loss'], label='Train Loss')\n",
    "plt.plot(history_initial['val_loss'] + history_fine['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('D:/Major Project/efficientnet/training_history.png')\n",
    "plt.close()\n",
    "print(\"Training history plot saved to 'D:/Major Project/efficientnet/training_history.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4addca90-a06c-4964-8c96-e2c4d656d514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
